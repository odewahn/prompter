{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompter","text":"<p>Prompter is a tool for developing content transformations with LLMs. It let's you create scripts that automate workflows, ike this:</p> <pre><code>load test.epub\ntransform html-to-md token-split --n=5000\ncomplete summarize-block.task\nsquash\ncomplete cleanup-summary.task\nwrite\n</code></pre> <p>It also has an IDE to help create and test your scripts and prompts:</p> <p></p> <p>With prompter you can:</p> <ul> <li>Load text from files or EPUBs into a database</li> <li>Transform text using a variety of transformations. For example, convert an EPUB to markdown, split a long block into smaller blocks, or split a block into sentences. A lot of this work is required to fit the text into the LLM's token limit.</li> <li>Filter out blocks of text. For example, you might only want to process one chapter in a book.</li> <li>Apply templated prompts to your blocks and send them to an LLM. You can use context in your prompts to make them more dynamic. For example, you might have a context file with keys like <code>title</code>, <code>author</code>, and <code>topic</code>. You can include these keys in your prompt templates.</li> <li>Create scripts so that you can automate your workflows for new content</li> </ul>"},{"location":"api-ref/","title":"API","text":"<p>Prompter has a simple UI that is used to power the browser-based IDE. You can use it as a standalone tool to create and run scripts, or you can use it as a library to build your own tools.</p> <p>This probably needs more endpoints, but it's a start.</p>"},{"location":"api-ref/#apigroups","title":"<code>/api/groups</code>","text":"<p>Get a list of all the groups in the database.</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"is_current\": 0,\n    \"command\": \"load data/*.txt\",\n    \"tag\": \"bbc-820\",\n    \"created_at\": \"2025-02-14 15:14:04\"\n  },\n  {\n    \"id\": 2,\n    \"is_current\": 1,\n    \"command\": \"transform new-line-split\",\n    \"tag\": \"zec-572\",\n    \"created_at\": \"2025-02-14 18:19:26\"\n  }\n]\n</code></pre>"},{"location":"api-ref/#apiblocks","title":"<code>/api/blocks</code>","text":"<p>Fetch all the blocks in the current group:</p> <pre><code>{\n  \"id\": 2,\n  \"is_current\": 1,\n  \"command\": \"transform new-line-split\",\n  \"tag\": \"zec-572\",\n  \"created_at\": \"2025-02-14 18:19:26\",\n  \"blocks\": [\n    {\n      \"id\": 3,\n      \"tag\": \"cat-essay.txt\",\n      \"group_id\": 2,\n      \"position\": 0,\n      \"created_at\": \"2025-02-14 18:19:26\",\n      \"content\": \"CATS ARE THE BEST.\",\n      \"token_count\": 4\n    },\n    {\n      \"id\": 4,\n      \"tag\": \"cat-essay.txt\",\n      \"group_id\": 2,\n      \"position\": 1,\n      \"created_at\": \"2025-02-14 18:19:26\",\n      \"content\": \"Man's best friend has historically been considered a dog. But dogs are not the only animal friend whose camaraderie people enjoy. For many people, a cat is their best friend. Despite what dog lovers may believe, cats make excellent house pets because they are good companions, they are civilized members of the household, and they are easy to care for. Let me tell you why.\",\n      \"token_count\": 65\n    },\n    ...\n    },\n    {\n      \"id\": 9,\n      \"tag\": \"dog-essay.txt\",\n      \"group_id\": 2,\n      \"position\": 6,\n      \"created_at\": \"2025-02-14 18:19:26\",\n      \"content\": \"Man's best friend has historically been considered a dog. But dogs are not the only animal friend whose camaraderie people enjoy. For many people, a dog is their best friend. Despite what dog lovers may believe, dogs make excellent house pets because they are good companions, they are civilized members of the household, and they are easy to care for. Let me tell you why.\",\n      \"token_count\": 65\n    },\n    ...\n]\n}\n</code></pre>"},{"location":"api-ref/#apiblocksgroup_id","title":"<code>/api/blocks/:group_id</code>","text":"<p>Fetch the blocks for a specific group. For example, <code>/api/blocks/bbc-820</code>:</p> <pre><code>{\n  \"id\": 1,\n  \"is_current\": 0,\n  \"command\": \"load data/*.txt\",\n  \"tag\": \"bbc-820\",\n  \"created_at\": \"2025-02-14 15:14:04\",\n  \"blocks\": [\n    {\n      \"id\": 1,\n      \"tag\": \"cat-essay.txt\",\n      \"group_id\": 1,\n      \"position\": 1,\n      \"created_at\": \"2025-02-14 15:14:04\",\n      \"content\": \"Man's best friend has historically been considered a dog. But dogs are not the only animal friend whose camaraderie people enjoy. For many people, a cat is their best friend. Despite what dog lovers may believe, cats make excellent house pets because they are good companions, they are civilized members of the household, and they are easy to care for. Let me tell you why....\",\n      \"token_count\": 362\n    },\n    {\n      \"id\": 2,\n      \"tag\": \"dog-essay.txt\",\n      \"group_id\": 1,\n      \"position\": 2,\n      \"created_at\": \"2025-02-14 15:14:04\",\n      \"content\": \"Man's best friend has historically been considered a dog. But dogs are not the only animal friend whose camaraderie people enjoy. For many people, a dog is their best friend. Despite what dog lovers may believe, dogs make excellent house pets because they are good companions, they are civilized members of the household, and they are easy to care for. Let me tell you why....\",\n      \"token_count\": 358\n    }\n  ]\n}\n</code></pre>"},{"location":"command-ref/","title":"Command Reference","text":""},{"location":"command-ref/#core-features","title":"Core Features","text":""},{"location":"command-ref/#load","title":"load","text":"<p>Load a file or files as a new group.</p> <ul> <li>Arguments:</li> <li><code>files</code> (required): List of files or URLs to load.</li> <li><code>--tag</code> (optional): Tag to use for the group.</li> <li>Example:</li> </ul> <pre><code>load *.txt --tag=text_files\n\nload book.epub\n\nload http://example.com\n</code></pre>"},{"location":"command-ref/#transform","title":"transform","text":"<p>Transform a block using specified transformations. If you chain multiple transformations together, they are applied in the order they are specified.</p> <ul> <li>Arguments:</li> <li><code>transformation</code> (required): Transformations to apply. Available transformations are:<ul> <li><code>token-split</code>: Breaks text into overlapping chunks of 1000 tokens overlapping by 10%.</li> <li><code>clean-epub</code>: Simplifies the HTML of an EPUB.</li> <li><code>html-h1-split</code>: Breaks HTML into blocks based on H1 tags.</li> <li><code>html-h2-split</code>: Breaks HTML into blocks based on H1 and H2 tags.</li> <li><code>html-to-md</code>: Converts HTML to Markdown.</li> <li><code>html-to-txt</code>: Converts HTML to plain text.</li> <li><code>new-line-split</code>: Splits text into blocks based on new lines.</li> <li><code>sentence-split</code>: Splits text into blocks based on sentences.</li> <li><code>strip-attributes</code>: Remove all attributes from HTML tags.</li> <li><code>extract-headers</code>: Extract HTML headers (through h4)</li> <li><code>feed-to-abridged-json</code>: Converts an RSS feed to an abridged JSON format Use --n to specify the number characters to use from the summary.</li> </ul> </li> <li><code>--tag</code> (optional): Tag to use for the group.</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li><code>--n</code> (optional): Number of tokens to split (default: 1000).</li> <li><code>--overlap</code> (optional): Overlap percentage (as an integer) for token-split (default: 10).</li> <li>Examples:</li> </ul> <pre><code>transform clean-epub --tag=cleaned --where=\"block_tag like 'ch%'\"\n\ntransform html-to-md token-split --n=1500\n</code></pre>"},{"location":"command-ref/#complete","title":"complete","text":"<p>Complete a block using OpenAI.</p> <ul> <li>Arguments:</li> <li><code>task</code> (required): Filename or URL of the task template.</li> <li><code>--persona</code> (optional): Filename or URL of the persona template.</li> <li><code>--context</code> (optional): context file (default: DEFAULT_CONTEXT_FN).</li> <li><code>--tag</code> (optional): Tag to use for the group.</li> <li><code>--model</code> (optional): Model to use (default: OPENAI_DEFAULT_MODEL).</li> <li><code>--temperature</code> (optional): Temperature to use (default: OPENAI_DEFAULT_TEMPERATURE).</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li>Example: <pre><code>complete summarize.jinja --tag=summary --model=gpt-4o --temperature=0.3\n</code></pre></li> </ul>"},{"location":"command-ref/#embed","title":"embed","text":"<p>Embeds the current blocks and saves them to a CSV file. ONLY WORKS WITH OPENAI</p> <ul> <li>Arguments:</li> <li><code>--fn</code> (optional): Filename pattern (jinja2) to write to (default: <code>embeddings.csv</code>).</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li><code>--model</code>: (optional): Model to use: <code>openai</code> (default) or <code>dummy</code> (writes all zeros)</li> <li>Example: <pre><code>embed --fn=\"my-embeddings.csv\"\n</code></pre></li> </ul>"},{"location":"command-ref/#run","title":"run","text":"<p>Run a file containing of prompter commands. For example, the following file of commands would allow you to summarize an epub file:</p> <pre><code>set FN test.epub\nload {{FN}}\nselect \"block_tag like 'chapter%'\"\ntransform clean-epub html-to-md token-split --n=1500\ncomplete summarize-block.task\nsquash\ncomplete cleanup-summary.task\nretag summary-{{block_tag}}.md\nwrite\n</code></pre> <ul> <li>Arguments:</li> <li><code>fn</code> (required): File or URL to run.</li> <li>Example: <pre><code>run script.prompter\n</code></pre></li> </ul>"},{"location":"command-ref/#browse","title":"browse","text":"<p>Opens a browser application so that you can view data, run commands, and experiement with different prompts.</p> <p></p>"},{"location":"command-ref/#data-management","title":"Data Management","text":""},{"location":"command-ref/#use","title":"use","text":"<p>Specifiy the name of the SQLite database you want to use to store your data. This database will be created in the current working directory. If you change the working directory, prompter will create a new database in the new directory using the same name.</p> <ul> <li>Arguments:</li> <li><code>db_name</code> (required): Database name to use.</li> <li>Example: <pre><code>use summary.db\n</code></pre></li> </ul>"},{"location":"command-ref/#blocks","title":"blocks","text":"<p>List all blocks.</p> <ul> <li>Arguments:</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li>Example: <pre><code>blocks --where=\"block_tag like 'ch%'\"\n</code></pre></li> </ul>"},{"location":"command-ref/#groups","title":"groups","text":"<p>List all groups.</p> <ul> <li>Arguments:</li> <li><code>--where</code> (optional): Where clause for the group.</li> <li>Example: <pre><code>groups --where=\"group_tag like 'my_group%'\"\n</code></pre></li> </ul>"},{"location":"command-ref/#checkout","title":"checkout","text":"<p>Checkout a group.</p> <ul> <li>Arguments:</li> <li><code>tag</code> (required): Tag to checkout. This can be:<ul> <li>tag: the name of the group to checkout</li> <li><code>latest</code>: checkout the latest group</li> <li><code>first</code>: checkout the first group</li> <li><code>next</code>: checkout the next group</li> <li><code>previous</code>: checkout the previous group</li> </ul> </li> <li>Example: <pre><code>checkout my_group\n</code></pre></li> </ul>"},{"location":"command-ref/#squash","title":"squash","text":"<p>Squash the current group into a new group by tag. Use this to combine blocks into a single block.</p> <ul> <li>Arguments:</li> <li><code>--delimiter</code> (optional): Delimiter to use (default: \"\\n\").</li> <li><code>--tag</code> (optional): Tag for the new group.</li> <li>Example: <pre><code>squash --delimiter=\"\\n\\n\" --tag=squashed_group\n</code></pre></li> </ul>"},{"location":"command-ref/#generating-output","title":"Generating Output","text":""},{"location":"command-ref/#write","title":"write","text":"<p>Write the current group to a file.</p> <ul> <li>Arguments:</li> <li><code>--fn</code> (optional): Filename pattern (jinja2) to write to (default: \"{{block_tag}}\").</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li>Examples:   Write each block to a file named after its tag:   <pre><code>write --fn=\"output/{{block_tag}}.txt\"\n</code></pre></li> </ul>"},{"location":"command-ref/#export","title":"export","text":"<p>Export all the current blocks to a json file.</p> <ul> <li> <p>Arguments:</p> </li> <li> <p><code>--fn</code> (optional): Filename pattern to write to (default: <code>blocks.json</code>).</p> </li> <li> <p>Example: <pre><code>export --fn=\"my_blocks.json\"\n</code></pre></p> </li> </ul>"},{"location":"command-ref/#speak","title":"speak","text":"<p>Convert the current block to audio files. ONLY WORKS WITH OPENAI</p> <ul> <li>Arguments:</li> <li><code>--fn</code> (optional): Filename pattern (jinja2) to write to (default: \"{{block_tag.split('.') | first}}-{{ '%04d' % position}}.mp3\").</li> <li><code>--where</code> (optional): Where clause for the blocks.</li> <li><code>--voice</code> (optional): Voice to use (default: \"alloy\").</li> <li><code>--preview</code> (optional): Preview the filenames.</li> <li>Example:</li> </ul> <pre><code>speak --fn=\"audio/{{block_tag}}.mp3\" --voice=alloy\n</code></pre>"},{"location":"command-ref/#context-variables","title":"Context Variables","text":"<p>Context variables are like environment variables that allow you to create symbols you can use in instructions, rather than literal strings. For example, you might use environment variables to set a source URL for the location of your task and persona prompts. When the script is run, the environment variables are replaced with their values. For example:</p> <pre><code>set SOURCE https://example.com\n</code></pre> <p>And then you can do something like this:</p> <pre><code>complete {{SOURCE}}/summarize.md --persona={{SOURCE}}/persona.md\n</code></pre> <p>You can pass environment variable into your scripts when they starts by creating a (bash) variable that begins with <code>PROMPTER\\_</code>. (Note that the \"PROMPTER_\" prefix will be stripped off.) For example, an environment variable created with <code>export PROMPTER_ENV=dev</code> automantically becomes available in the prompter environment as <code>ENV=dev</code>.</p>"},{"location":"command-ref/#set","title":"set","text":"<p>Set an environment variable.</p> <ul> <li>Arguments:</li> <li><code>key</code> (required): Key to set.</li> <li><code>value</code> (required): Value to set.</li> <li>Example: <pre><code>set SOURCE https://example.com\n</code></pre></li> </ul>"},{"location":"command-ref/#unset","title":"unset","text":"<p>Remove an environment variable.</p> <ul> <li>Arguments:</li> <li><code>key</code> (required): Key to remove.</li> <li>Example: <pre><code>unset SOURCE\n</code></pre></li> </ul>"},{"location":"command-ref/#other-commands","title":"Other Commands","text":""},{"location":"command-ref/#version","title":"version","text":"<p>Print the version of the application.</p> <ul> <li>Example: <pre><code>version\n</code></pre></li> </ul>"},{"location":"command-ref/#exit","title":"exit","text":"<p>Exit the REPL (Read-Eval-Print Loop).</p> <ul> <li>Example:</li> </ul> <pre><code>exit\n</code></pre>"},{"location":"concepts/","title":"Understanding Prompter","text":"<p>Prompter is a tool for applying Large Language Model (LLM) prompts to content at scale. It provides both a command-line REPL interface and a GUI for managing the workflow of:</p> <ol> <li>Loading content from various sources</li> <li>Processing that content into LLM-friendly chunks</li> <li>Applying prompts systematically</li> <li>Managing and storing the results</li> </ol>"},{"location":"concepts/#core-concepts","title":"Core Concepts","text":"<p>Before diving in, it's important to understand these key concepts:</p>"},{"location":"concepts/#blocks","title":"Blocks","text":"<p>A block is a chunk of text that can be processed by an LLM. Blocks are the fundamental unit in Prompter:</p> <ul> <li>They should ultimately fit within an LLM's context window (typically 8K tokens) via a series of transformations</li> <li>Can be in various formats (HTML, Markdown, plain text)</li> <li>Have metadata like IDs and tags for tracking</li> </ul>"},{"location":"concepts/#groups","title":"Groups","text":"<p>Groups are collections of related blocks:</p> <ul> <li>Created when you load, transform, or combine blocks; thet are also created when you perform a completion ask with an LLM</li> <li>Have a unique tag for identification (auto-generated or user-specified)</li> <li>Only one group is \"active\" at a time (the current group)</li> </ul> <p>Each group has a unique tag that can be used to identify it. You can supply a tag when you create a group, or Prompter will generate one for you. Use the <code>checkout &lt;tag&gt;</code> command to set the current group to a specific tag. (There are also reserved tag names <code>first</code>, <code>last</code>, <code>next</code> and <code>previous</code>).</p> <p>Suppying your own tag can be useful if you want to refer to the group later. For example, you might tag a group with a name like <code>final</code> if it represents the final step in a series of transformations. You can then perform various operations like completions, but then use the <code>checkout final</code> command to go back to the <code>final</code> group.</p>"},{"location":"concepts/#completions","title":"Completions","text":"<p>A completion is the result of applying a prompt template to a block and then sending it to an LLM.</p>"},{"location":"concepts/#tasks","title":"Tasks","text":"<p>A task is a prompt that is applied to a block. Tasks use jinja templating to create prompts that can be applied to blocks. For example, a task might ask the LLM to summarize a block of text or generate a list of key points.</p> <pre><code>Here is a selection of text from a book called {{title}} by {{authors}}. Please summarize it in 250 words or fewer:\n\n{{content}}\n</code></pre>"},{"location":"concepts/#personas","title":"Personas","text":"<p>If a task tells the LLM what to do, a persona tells it how to do it. Personas are a way to customize the behavior of the LLM by providing it with additional context. For example, you might have a persona that tells the LLM to write in the style of a particular author or to use a specific tone.</p>"},{"location":"concepts/#context-variables","title":"Context variables","text":"<p>Context variables are key-value pairs that can be used in tasks and personas. They allow you to provide additional context to the LLM. For example, you might have context variables for the title and author of a book that you are summarizing.</p> <p>You can save context variables in a YAML file that you can supply with the <code>--context</code> flag when you run a completion, or you can set them directly using the <code>set</code> command. For example:</p> <pre><code>set TITLE \"The Great Gatsby\"\nset AUTHOR \"F. Scott Fitzgerald\"\n</code></pre> <p>Note that Prompter will automatically capitalize the keys of context variables, so you can use them in your templates like this:</p> <pre><code>Here is a selection of text from a book called {{TITLE}} by {{AUTHOR}}. Please summarize it in 250 words or fewer:\n\n{{content}}\n</code></pre> <p>Finally, you can use environment variables set in the shell to provide context variables to Prompter by prefacing them with <code>PROMPTER_</code>. For example, you might set the <code>TITLE</code> and <code>AUTHOR</code> environment variables in your shell before running Prompter.</p> <pre><code>export PROMPTER_TITLE=\"The Great Gatsby\"\nexport PROMPTER_AUTHOR=\"F. Scott Fitzgerald\"\n</code></pre>"},{"location":"concepts/#workflows","title":"Workflows","text":"<p>A typical Prompter workflow follows these steps:</p> <ol> <li>Load content into the SQLite database</li> <li>Transform content into LLM-friendly format (e.g., HTML \u2192 Markdown)</li> <li>Split content into appropriate block sizes</li> <li>Apply prompts (tasks + personas) to blocks</li> <li>Manage the results as new blocks</li> </ol> <p>Commands in prompter have a basic syntax that consists of a command name and a set of arguments that follow typical command line format. For example, completing a prompt looks like this:</p> <pre><code>complete extract-key-points.task --persona=oreilly-short.txt --context=metadata.yaml\n</code></pre> <p>You can find full documentation for prompter at https://github.com/odewahn/prompter.</p> <p>The following sections assume you have followed the instructions above and downloaded some content and prompts into a root directory.</p>"},{"location":"concepts/#installation-and-setup","title":"Installation and setup","text":"<p>Download and install prompter from the releases page.</p> <p>Next, create a working direcory. For the purposes of this walkthrough, let's assume all files are in a directory called <code>genai-tutorial</code>:</p> <pre><code>cd ~\nmkdir genai-tutorial\ncd genai-tutorial\ncode .\n</code></pre> <p>Within VSCode, open a terminal and type <code>prompter</code>. Your environment should look something like this:</p> <p></p>"},{"location":"concepts/#summarizing-an-essay","title":"Summarizing an Essay","text":"<p>Let's start with a simple example -- summarizing an essay. The main things to understand about using prompter are:</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#summarize-an-epub","title":"Summarize an EPUB","text":"<p>Here is an example of how you might make a summary of an EPUB book. It works by:</p> <ul> <li>splitting each chapter into overlapping blocks of text</li> <li>summarizing each block using a template</li> <li>squasing the summaries into a single summary</li> <li>using another prompt to clean up the summary</li> </ul> <p>Here's the full program in a <code>Prompterfile</code>:</p> <pre><code>load test.epub\nselect \"block_tag like 'chapter%'\"\ntransform clean-epub html-to-md token-split --n=5000\ncomplete summarize-block.task\nsquash\ncomplete cleanup-summary.task\nretag summary-{{block_tag}}.md\nwrite\n</code></pre> <p>Here is the first task, which summarizes a single block of text:</p> <p><code>summarize-block.task</code></p> <p>Summarize the following block of text:</p> <p>{{content}}</p> <p>Do this in 250 words or fewer using markdown fomatting. Focus on adding bullet lists.</p> <p>Here is the second task, which cleans up the \"squashed\" summaries of all the blocks:</p> <p><code>task-summarize-summary.md</code></p> <p>This is a summary of a chapter that was constucted from overlapping chunks of text from a longer work:</p> <p>{{content}}</p> <p>Summarize it into 250 words or fewer.</p>"},{"location":"examples/#make-an-audio-file-of-github-trending-repos","title":"Make an audio file of GitHub trending repos","text":"<p>This example use the mshibanami/GitHubTrendingRSS project to convert an RSS feed (in this case, RSS 2.0) of GitHub trending projects into an audio file. Here's how it works:</p> <ul> <li><code>load</code> the feed from the \"All Languages\" feed on GitHub Trending RSS</li> <li><code>transform</code> the feed into json using the <code>feed-to-abridged-json</code> command (there are several ways to summarize the feed data)</li> <li><code>complete</code> a prompt that converts the json into a markdown file</li> <li><code>speak</code> to make the audio file</li> </ul> <p>Here's an example of the output of the <code>feed-to-abridged-json</code> command when run on the feed:</p> <pre><code>[\n    {\n        \"title\": \"langgenius/dify\",\n        \"link\": \"https://github.com/langgenius/dify\",\n        \"summary\": \"&lt;p&gt;Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;&lt;img alt=\\\"cover-v5-optimized\\\" src=\\\"https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab\\\" /&gt;&lt;/p&gt; \\n&lt;p align=\\\"center\\\"&gt; \\ud83d\\udccc &lt;a href=\\\"https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast\\\"&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt; &lt;/p&gt; \\n&lt;p align=\\\"center\\\"&gt; &lt;a href=\\\"https://cloud.dify.ai\\\"&gt;Dify Cloud&lt;/a&gt; \\u00b7 &lt;a href=\\\"https://docs.dify.ai/getting-started/install-self-hosted\\\"&gt;Self-hosting&lt;/a&gt; \\u00b7 &lt;a href=\\\"https://docs.dify.ai\\\"&gt;Documentation&lt;/a&gt; \\u00b7 &lt;a href=\\\"https://udify.app/chat/22L1zSxg6yW1cWQg\\\"&gt;Enterprise inquiry&lt;/a&gt; &lt;/p&gt; \\n&lt;p align=\\\"center\\\"&gt; &lt;a href=\\\"https://dify.ai\\\" target=\\\"_blank\\\"&gt; &lt;img alt=\\\"Static Badge\\\" src=\\\"https://img.shields.io/badge/Product-F04438\"\n    },\n    ...\n]\n</code></pre> <p>Here's the <code>Prompterfile</code>:</p> <pre><code>load https://mshibanami.github.io/GitHubTrendingRSS/weekly/all.xml\ntransform feed-to-abridged-json\ncomplete summarize-trending-repos.task\nspeak\n</code></pre> <p>Here's the <code>summarize-trending-repos.task</code> task:</p> <p><code>summarize-trending-repos.task</code></p> <p>The prompt goes here</p>"},{"location":"examples/#break-an-epub-into-chunks-and-compute-embeddings","title":"Break an EPUB into chunks and compute embeddings","text":"<p>This Prompterfile shows how to break an EPUB into chunks of ~500 words and compute their embeddings. The embeddings are saved in a CSV file and the chunks are saved in a JSON file.</p> <pre><code>#! sh\n# Set filename variable that excludes an extension\nset FN my-ebook\nload {{FN}}.epub\nselect \"block_tag like 'ch%.html'\"\ntransform clean-epub html-to-md\ntransform token-split --n=500 --overlap=0\nexport --fn=out-{{ FN }}.json\nembed --fn=out-{{ FN }}.csv\n</code></pre>"},{"location":"examples/#using-jinja-in-a-prompterfile","title":"Using Jinja in a Prompterfile","text":"<p>You can use Jinja template constructs to create more complex logic in a Prompterfile. For example, here's an example that uses Jinja to loop over a list of durations and generate a series of tasks that summarize a block of text:</p> <pre><code>load data/source/*.html\nselect \"block_tag like '%-ch%'\"\ntransform strip-attributes extract-headers\ncomplete task-summarize-block.txt\nretag gist\nsquash --tag=squashed\n{% for duration in ['30-seconds', '2-minutes'] %}\n   checkout squashed\n   # Set an environment variable to set context that can be used in the prompt\n   set DURATION {{duration}}\n   complete task-get-the-gist-duration.txt --context=data/metadata.yaml --model=gpt-4o\n   retag gist-{{duration}}\n   speak --speed=1.2\n{% endfor %}\n</code></pre>"},{"location":"examples/#using-retag-to-change-filenames","title":"Using <code>retag</code> to change filenames","text":""},{"location":"installation/","title":"Installation","text":"<p>Prompter runs on OSX and Linux. You'll find the latest release on the project's releases page.</p>"},{"location":"installation/#osx","title":"OSX","text":"<p>Download and install the package. Even though this is a Python prject, the release is a compiled binary and will require no other dependencies.</p>"},{"location":"installation/#linux","title":"Linux","text":"<p>You can download the binary and run it directly. Here's how you can do it on Ubuntu:</p> <pre><code>wget https://github.com/odewahn/prompter/releases/download/0.6.1/prompter.ubuntu\nmv prompter.ubuntu prompter\nchmod +x prompter\n</code></pre>"},{"location":"installation/#authentication-with-openai","title":"Authentication with OpenAI","text":"<p>Prompter requires an API key from OpenAI. You can get one by signing up for an account at OpenAI. Once you have an account, you can find your API key on the API settings page.</p> <p>Once you have your API key, you can set it as an environment variable like this:</p> <pre><code>export OPENAI_API_KEY=your-api-key\n</code></pre> <p>Prompter will warn you if you haven't set this variable.</p>"}]}